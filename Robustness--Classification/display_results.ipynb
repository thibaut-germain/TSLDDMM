{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_datasets = [\n",
    "    \"Cricket\", \n",
    "    \"ERing\", \n",
    "    \"Handwriting\",\n",
    "    \"Libras\",\n",
    "    \"NATOPS\",\n",
    "    \"RacketSports\",\n",
    "    \"UWaveGestureLibrary\",\n",
    "    \"ArticularyWordRecognition\", \n",
    "]\n",
    "\n",
    "univariate_datasets = [\n",
    "    \"ArrowHead\", \n",
    "    \"BME\", \n",
    "    \"ECG200\",\n",
    "    \"FacesUCR\",\n",
    "    \"GunPoint\", \n",
    "    \"PhalangesOutlinesCorrect\",\n",
    "    \"Trace\",\n",
    "]\n",
    "\n",
    "valid_datasets = univariate_datasets + multivariate_datasets\n",
    "\n",
    "lst = [[ds,\"univariate\"] for ds in univariate_datasets] + [[ds, \"multivariate\"] for ds in multivariate_datasets]\n",
    "ds_df = pd.DataFrame(lst, columns= [\"dataset\",\"type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape analysis classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      " & model & Shape-FPCA (2024) & TCLR (2024) & LDDMM (2008) & TS-LDDMM (ours) \\\\\n",
      "type & dataset &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{7}{*}{univariate} & ArrowHead & 0.18 & \\textbf{29.72} & 0.84 & \\underline{0.91} \\\\\n",
      " & BME & 0.16 & \\textbf{8.02} & 0.82 & \\underline{1.00} \\\\\n",
      " & ECG200 & 0.40 & \\textbf{5.89} & \\underline{0.81} & 0.79 \\\\\n",
      " & FacesUCR & 0.08 & \\textbf{77.90} & 0.69 & \\underline{0.86} \\\\\n",
      " & GunPoint & 0.93 & \\textbf{11.42} & 0.83 & \\underline{1.00} \\\\\n",
      " & PhalangesOutlinesCorrect & 0.39 & \\textbf{40.95} & \\underline{0.53} & 0.52 \\\\\n",
      " & Trace & 0.55 & \\textbf{33.96} & 0.46 & \\underline{1.00} \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow[t]{8}{*}{multivariate} & ArticularyWordRecognition & -- & -- & \\underline{0.98} & \\textbf{1.00} \\\\\n",
      " & Cricket & -- & -- & \\underline{0.77} & \\textbf{0.93} \\\\\n",
      " & ERing & -- & -- & \\underline{0.95} & \\textbf{0.98} \\\\\n",
      " & Handwriting & -- & -- & \\underline{0.22} & \\textbf{0.44} \\\\\n",
      " & Libras & -- & -- & \\underline{0.56} & \\textbf{0.60} \\\\\n",
      " & NATOPS & -- & -- & \\underline{0.82} & \\textbf{0.82} \\\\\n",
      " & RacketSports & -- & -- & \\textbf{0.83} & \\underline{0.79} \\\\\n",
      " & UWaveGestureLibrary & -- & -- & \\underline{0.72} & \\textbf{0.81} \\\\\n",
      "\\cline{1-6}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpca_df = pd.read_csv(\"results/shape-fpca_0.0_0.csv\",index_col=0)\n",
    "fpca_df[\"model\"] = \"Shape-FPCA (2024)\"\n",
    "tclr_df = pd.read_csv(\"results/tclr_0.0_0.csv\",index_col=0)\n",
    "tclr_df[\"model\"] = \"TCLR (2024)\"\n",
    "lddmm_df = pd.read_csv(\"results/lddmm_methods_0.0_0.csv\",index_col=0)\n",
    "lddmm_df[\"model\"] = lddmm_df[\"model\"].apply(lambda x : \"TS-LDDMM (ours)\" if x == \"ts-lddmm\" else \"LDDMM (2008)\")\n",
    "df = pd.concat([fpca_df,tclr_df,lddmm_df]).reset_index(drop = True)\n",
    "df = pd.merge(df,ds_df,on=\"dataset\")\n",
    "df = pd.pivot_table(df,\"fscore\",[\"type\",\"dataset\"],\"model\",aggfunc=\"first\")\n",
    "df = df.loc[[\"univariate\",\"multivariate\"]]\n",
    "df = df[[\"Shape-FPCA (2024)\", \"TCLR (2024)\", \"LDDMM (2008)\",\"TS-LDDMM (ours)\"]]\n",
    "df_s = df.style.format(\"{:.2f}\")\n",
    "\n",
    "# loop through rows and find which column for each row has the highest value\n",
    "for row in df.index:\n",
    "    col = df.loc[row].idxmax()\n",
    "    col2 = df.loc[row].nlargest(2).idxmin()\n",
    "    # redo formatting for a specific cell\n",
    "    df_s = df_s.format(lambda x: \"\\\\textbf{\" + f'{x:.2f}' + \"}\", subset=(row, col))\n",
    "    df_s = df_s.format(lambda x: \"\\\\underline{\" + f'{x:.2f}' + \"}\", subset=(row, col2))\n",
    "\n",
    "row,col = np.where(df.isna())\n",
    "row = df.index[row]\n",
    "col = df.columns[col]\n",
    "df_s.format(lambda x : \"--\",subset=(row,col))\n",
    "\n",
    "\n",
    "print(df_s.to_latex(hrules = True, clines = \"skip-last;data\",multirow_align = \"t\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mapping = dict(\n",
    "    rnn = \"RNN (1999)\",\n",
    "    lstm = 'LSTM (1997)',\n",
    "    gru = \"GRU (2014)\",\n",
    "    mtan = 'MTAN (2021)',\n",
    "    miam = 'MIAM (2022)',\n",
    "    neuralsde_1_18 = 'Neural SDE (2019)', \n",
    "    neuralsde_4_17 = 'Neural LNSDE (2024)',\n",
    ")\n",
    "model_mapping['ode-lstm'] = 'ODE-LSTM (2020)'\n",
    "model_mapping['lddmm'] = 'LDDMM (2008)'\n",
    "model_mapping['ts-lddmm'] = 'TS-LDDMM (ours)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = [\n",
    "    'rnn', 'lstm', 'gru',\n",
    "    'mtan', 'miam',\n",
    "    'ode-lstm',\n",
    "    \"neuralsde_1_18\", \"neuralsde_4_17\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\n",
    "    \"RNN (1999)\",\n",
    "    'LSTM (1997)',\n",
    "    \"GRU (2014)\",\n",
    "    'MTAN (2021)',\n",
    "    'MIAM (2022)',\n",
    "    'ODE-LSTM (2020)',\n",
    "    'Neural SDE (2019)', \n",
    "    'Neural LNSDE (2024)',\n",
    "    'LDDMM (2008)',\n",
    "    'TS-LDDMM (ours)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for missing_rate in [0.0,0.3,0.5,0.7]:\n",
    "    tlst = []\n",
    "    for dataset in valid_datasets: \n",
    "        for model in model_name_list: \n",
    "            path = \"results/{}/{}/{}_{}_{}_0\".format(dataset,missing_rate,dataset,missing_rate,model)\n",
    "            with open(path,\"rb\") as f:\n",
    "                score = pickle.load(f)[-1][\"f1score\"]\n",
    "                tlst.append([dataset,model,score])\n",
    "    df = pd.DataFrame(tlst, columns=[\"dataset\",\"model\",\"score\"])\n",
    "    df[\"missing_rate\"] = missing_rate\n",
    "    lst.append(df)\n",
    "\n",
    "for missing_rate in [0.0,0.3,0.5,0.7]: \n",
    "    df = pd.read_csv(\"results/lddmm_methods_{}_0.csv\".format(missing_rate),index_col=0)\n",
    "    df[\"missing_rate\"] = missing_rate\n",
    "    df[\"score\"] = df[\"fscore\"]\n",
    "    df = df[[\"dataset\", \"model\", \"score\", \"missing_rate\"]]\n",
    "    lst.append(df)\n",
    "\n",
    "df = pd.concat(lst)\n",
    "df['model'] = df['model'].apply(lambda x : model_mapping[x])\n",
    "df[\"score\"] = df[\"score\"].apply(lambda x : -x )\n",
    "\n",
    "df = pd.pivot_table(df,\"score\",[\"missing_rate\",\"dataset\"],\"model\", aggfunc=\"first\")\n",
    "df = df.rank(axis=1,method=\"max\").reset_index()\n",
    "df = df.drop([\"dataset\"],axis=1)\n",
    "df = df.groupby(\"missing_rate\").mean()\n",
    "df = df[model_order]\n",
    "df = df.reset_index()\n",
    "rank_df = pd.melt(df,id_vars=\"missing_rate\")\n",
    "rank_df = rank_df.set_index([\"model\",\"missing_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "missing_rate & 0.000000 & 0.300000 & 0.500000 & 0.700000 \\\\\n",
      "model &  &  &  &  \\\\\n",
      "\\midrule\n",
      "RNN (1999) & $0.64 \\pm 0.21$  & 6.2 & $0.53 \\pm 0.23$  & 6.6 & $0.48 \\pm 0.21$  & 7.2 & $0.44 \\pm 0.21$  & 6.07 \\\\\n",
      "LSTM (1997) & $0.61 \\pm 0.29$  & 6.0 & $0.57 \\pm 0.29$  & 6.27 & $0.53 \\pm 0.25$  & 6.07 & $0.51 \\pm 0.29$  & 5.27 \\\\\n",
      "GRU (2014) & $0.71 \\pm 0.26$  & 4.2 & $0.68 \\pm 0.28$  & 4.27 & $0.66 \\pm 0.28$  & 3.73 & $0.59 \\pm 0.28$  & 3.67 \\\\\n",
      "MTAN (2021) & $0.59 \\pm 0.28$  & 7.13 & $0.58 \\pm 0.28$  & 5.8 & $0.54 \\pm 0.29$  & 5.33 & $0.51 \\pm 0.28$  & 5.0 \\\\\n",
      "MIAM (2022) & $0.48 \\pm 0.35$  & 6.93 & $0.42 \\pm 0.33$  & 8.27 & $0.47 \\pm 0.31$  & 6.93 & $0.35 \\pm 0.31$  & 7.6 \\\\\n",
      "ODE-LSTM (2020) & $0.63 \\pm 0.24$  & 6.0 & $0.57 \\pm 0.25$  & 6.53 & $0.51 \\pm 0.24$  & 7.27 & $0.45 \\pm 0.23$  & 6.73 \\\\\n",
      "Neural SDE (2019) & $0.48 \\pm 0.28$  & 7.67 & $0.47 \\pm 0.26$  & 7.47 & $0.45 \\pm 0.27$  & 7.13 & $0.45 \\pm 0.25$  & 6.0 \\\\\n",
      "Neural LNSDE (2024) & $0.7 \\pm 0.27$  & 3.87 & $0.68 \\pm 0.29$  & 4.0 & $0.67 \\pm 0.25$  & 3.53 & $0.66 \\pm 0.23$  & 2.47 \\\\\n",
      "LDDMM (2008) & $0.72 \\pm 0.2$  & 4.53 & $0.7 \\pm 0.21$  & 4.2 & $0.57 \\pm 0.25$  & 5.0 & $0.4 \\pm 0.25$  & 7.13 \\\\\n",
      "TS-LDDMM (ours) & $0.83 \\pm 0.18$  & 2.93 & $0.8 \\pm 0.18$  & 2.07 & $0.7 \\pm 0.26$  & 3.33 & $0.51 \\pm 0.27$  & 5.67 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:26: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:26: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/tmp/ipykernel_1688274/3397696954.py:26: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  df[\"mean_std\"] = df.apply(lambda row : \"${} \\pm {}$  & {}\".format(np.round(row[0],2),np.round(row[1],2),np.round(row[2],2)),axis=1)\n",
      "/tmp/ipykernel_1688274/3397696954.py:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df[\"mean_std\"] = df.apply(lambda row : \"${} \\pm {}$  & {}\".format(np.round(row[0],2),np.round(row[1],2),np.round(row[2],2)),axis=1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for missing_rate in [0.0,0.3,0.5,0.7]:\n",
    "    tlst = []\n",
    "    for dataset in valid_datasets: \n",
    "        for model in model_name_list: \n",
    "            path = \"results/{}/{}/{}_{}_{}_0\".format(dataset,missing_rate,dataset,missing_rate,model)\n",
    "            with open(path,\"rb\") as f:\n",
    "                score = pickle.load(f)[-1][\"f1score\"]\n",
    "                tlst.append([dataset,model,score])\n",
    "    df = pd.DataFrame(tlst, columns=[\"dataset\",\"model\",\"score\"])\n",
    "    df[\"missing_rate\"] = missing_rate\n",
    "    lst.append(df)\n",
    "\n",
    "for missing_rate in [0.0,0.3,0.5,0.7]: \n",
    "    df = pd.read_csv(\"results/lddmm_methods_{}_0.csv\".format(missing_rate),index_col=0)\n",
    "    df[\"missing_rate\"] = missing_rate\n",
    "    df[\"score\"] = df[\"fscore\"]\n",
    "    df = df[[\"dataset\", \"model\", \"score\", \"missing_rate\"]]\n",
    "    lst.append(df)\n",
    "        \n",
    "df = pd.concat(lst)\n",
    "df['model'] = df['model'].apply(lambda x : model_mapping[x])\n",
    "mean_df = df.groupby([\"model\",\"missing_rate\"]).score.mean()\n",
    "std_df = df.groupby([\"model\",\"missing_rate\"]).score.std()\n",
    "df = pd.concat([mean_df,std_df,rank_df],axis=1)\n",
    "df[\"mean_std\"] = df.apply(lambda row : \"${} \\pm {}$  & {}\".format(np.round(row[0],2),np.round(row[1],2),np.round(row[2],2)),axis=1)\n",
    "df = df[\"mean_std\"].reset_index()\n",
    "df = pd.pivot_table(df,\"mean_std\",\"model\",\"missing_rate\",aggfunc=\"first\")\n",
    "df = df.loc[model_order]\n",
    "print(df.style.to_latex(hrules = True, clines = \"skip-last;data\",multirow_align = \"t\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakeoff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
